# -*- coding: utf-8 -*-
"""bussiness_risk_radar_1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qN0N5jNXENJ9sUnci3nQQn3iOZ1_uu_q

<h2 style="text-align: center;">BUSINESS RISK RADAR</h2>
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv("/content/archive (1).zip", compression="zip")
df.head()

print("Shape of dataset:", df.shape)
print("\nColumns:\n", df.columns)
print("\nInfo:\n")
df.info()
print("\nSummary Stats:\n")
print(df.describe())

"""Data Cleaning"""

df = df.drop_duplicates()

df["profit_mil"] = df["profit_mil"].fillna(0)
df["revenue_mil"] = df["revenue_mil"].fillna(df["revenue_mil"].median())


df["year"] = df["year"].astype(int)
df["rank"] = df["rank"].astype(int)
df["revenue_mil"] = pd.to_numeric(df["revenue_mil"], errors="coerce")
df["profit_mil"] = pd.to_numeric(df["profit_mil"], errors="coerce")

print("Cleaned dataset shape:", df.shape)

print("\nMissing values:\n", df.isnull().sum())

df["sector"] = df["sector"].fillna("Unknown")
df["headquarters_city"] = df["headquarters_city"].fillna("Unknown")
df["headquarters_state"] = df["headquarters_state"].fillna("Unknown")


for col in ["market_value_mil","asset_mil","employees"]:
    df[col] = df[col].fillna(df[col].median())

df = df.drop(columns=["founder_is_ceo","female_ceo","newcomer_to_fortune_500","global_500"])

print("Missing values after cleaning:\n", df.isnull().sum())

"""Exploratory Data Analysis (EDA)"""

import plotly.express as px
import plotly.graph_objects as go


fig = px.histogram(df, x="revenue_mil", nbins=30, title="Distribution of Revenue", marginal="box", opacity=0.7)
fig.show()


fig = px.histogram(df, x="profit_mil", nbins=30, title="Distribution of Profit", marginal="box", opacity=0.7)
fig.show()

corr = df[["revenue_mil","profit_mil","market_value_mil","asset_mil","employees"]].corr()
fig = px.imshow(corr,
                text_auto=True,
                color_continuous_scale="RdBu_r",
                title="Correlation Heatmap")
fig.show()

top_2023 = df[df["year"]==2023].sort_values(by="revenue_mil", ascending=False).head(10)
print("\n--- Top 10 Companies by Revenue (2023) ---")
print(top_2023[["name","revenue_mil","profit_mil"]])

fig = px.bar(top_2023,
             x="revenue_mil",
             y="name",
             orientation="h",
             title="Top 10 Companies by Revenue (2023)",
             hover_data=["profit_mil"])
fig.show()

companies = ["Walmart", "Apple"]
trend = df[df["name"].isin(companies)]

fig = px.line(trend,
              x="year",
              y="revenue_mil",
              color="name",
              markers=True,
              title="Revenue Trend: Walmart vs Apple")
fig.show()

fig = px.scatter(df[df["year"]==2023],
                 x="revenue_mil",
                 y="profit_mil",
                 color="name",
                 size="market_value_mil",
                 hover_data=["rank","industry"],
                 title="Profit vs Revenue (2023)")
fig.show()

"""Feature Engineering"""

df["ProfitMargin"] = np.where(df["revenue_mil"] > 0,
                              (df["profit_mil"] / df["revenue_mil"]) * 100,
                              0)


df["RiskFlag"] = np.where(df["profit_mil"] < 0, 1, 0)

industry_avg = df.groupby(["year","industry"])["revenue_mil"].mean().reset_index()
industry_avg.rename(columns={"revenue_mil":"IndustryAvgRevenue"}, inplace=True)

df = pd.merge(df, industry_avg, on=["year","industry"], how="left")

df.head()

"""Machine Learning Model (Linear Regression)"""

features = ["revenue_mil", "market_value_mil", "asset_mil", "employees", "IndustryAvgRevenue"]
X = df[features]
y = df["profit_mil"]



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("R2 Score:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))

plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel("Actual Profit")
plt.ylabel("Predicted Profit")
plt.title("Linear Regression: Actual vs Predicted Profit")
plt.show()

coef_df = pd.DataFrame({"Feature": features, "Coefficient": model.coef_})
display(coef_df)

industry_share = df[df["year"]==2023]["industry"].value_counts().head(10)
sns.barplot(x="revenue_mil", y="name", data=top_2023)
plt.xlabel("Revenue (Millions)")
plt.ylabel("Company")
plt.title("Top 10 Companies by Revenue (2023)")
plt.tight_layout()
plt.show()

loss_companies = df[(df["year"]==2023) & (df["profit_mil"]<0)]
print("Companies in Loss (2023):\n", loss_companies[["name","revenue_mil","profit_mil"]].head(10))

df.to_csv("cleaned_fortune500.csv", index=False)

"""**test case**

"""

def calculate_risk_score(probability, impact):
    return probability * impact

import unittest

class TestRiskFunctions(unittest.TestCase):
    def test_calculate_risk_score(self):
        # Case 1: 0.5 * 100 should be 50
        self.assertEqual(calculate_risk_score(0.5, 100), 50)

        # Case 2: 1 * 200 should be 200
        self.assertEqual(calculate_risk_score(1, 200), 200)

        # Case 3: Wrong result should fail
        self.assertNotEqual(calculate_risk_score(0.3, 50), 100)

unittest.main(argv=[''], exit=False)  # runs the test inside Jupyter

"""## Conclusion

- The linear regression model explained around XX% of the variance in company profits.  
- Revenue, assets, and number of employees were the strongest predictors of profit.  
- Walmart, Apple, and ExxonMobil dominated revenue, while some industries showed negative profit margins, signaling risk.  
- The Business Risk Radar can be extended with more advanced models (Random Forest, XGBoost) for better predictions.  
"""